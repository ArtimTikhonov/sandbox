# =============================================================================
# DOCKER COMPOSE КОНФИГУРАЦИЯ ДЛЯ МИКРОСЕРВИСНОЙ ЭКОСИСТЕМЫ + ELK STACK
# =============================================================================
# Добавлены: Elasticsearch, Logstash, Kibana для централизованного логирования

version: '3.8'

services:

  # ---------------------------------------------------------------------------
  # FRONTEND - REACT ПРИЛОЖЕНИЕ С NGINX
  # ---------------------------------------------------------------------------
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
      target: frontend
      args:
        REBUILD_DATE: ${REBUILD_DATE:-$(date +%Y%m%d%H%M%S)}
    container_name: frontend
    ports:
      - "3000:80"
    networks:
      - sandbox-network
    depends_on:
      - api-gateway
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # ELK STACK - ELASTICSEARCH
  # ---------------------------------------------------------------------------
  elasticsearch:
    image: elasticsearch:8.8.2
    container_name: elasticsearch
    environment:
      # Отключаем security для упрощения настройки (не для production!)
      - xpack.security.enabled=false
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"  # Ограничиваем память
      - cluster.name=sandbox-cluster
      - node.name=sandbox-node
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - sandbox-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # ELK STACK - LOGSTASH
  # ---------------------------------------------------------------------------
  logstash:
    image: logstash:8.8.2
    container_name: logstash
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"  # Beats input
      - "5000:5000"  # TCP input для приложений
      - "9600:9600"  # Logstash API
    environment:
      LS_JAVA_OPTS: "-Xms256m -Xmx256m"
      ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
    networks:
      - sandbox-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # ELK STACK - KIBANA
  # ---------------------------------------------------------------------------
  kibana:
    image: kibana:8.8.2
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      # Отключаем security для упрощения
      XPACK_SECURITY_ENABLED: false
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: "something_at_least_32_characters_long_for_encryption_key"
    networks:
      - sandbox-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # ZOOKEEPER - КООРДИНАТОР ДЛЯ KAFKA
  # ---------------------------------------------------------------------------
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - sandbox-network

  # ---------------------------------------------------------------------------
  # KAFKA - БРОКЕР СООБЩЕНИЙ
  # ---------------------------------------------------------------------------
  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9093
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - sandbox-network

  # ---------------------------------------------------------------------------
  # KAFKA UI - ВЕБ-ИНТЕРФЕЙС ДЛЯ УПРАВЛЕНИЯ KAFKA
  # ---------------------------------------------------------------------------
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: 'true'
      KAFKA_CLUSTERS_0_READONLY: 'false'
    networks:
      - sandbox-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # REDIS - КЕШ И ХРАНИЛИЩЕ СЕССИЙ
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - sandbox-network

  # ---------------------------------------------------------------------------
  # POSTGRESQL - ОСНОВНАЯ РЕЛЯЦИОННАЯ БД
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:16
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: sandbox
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - sandbox-network

  # ---------------------------------------------------------------------------
  # PROMETHEUS - СБОР И ХРАНЕНИЕ МЕТРИК
  # ---------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - sandbox-network

  # ---------------------------------------------------------------------------
  # GRAFANA - ВИЗУАЛИЗАЦИЯ МЕТРИК И ДАШБОРДЫ
  # ---------------------------------------------------------------------------
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - sandbox-network
    depends_on:
      - prometheus

  # ---------------------------------------------------------------------------
  # API GATEWAY - ЕДИНАЯ ТОЧКА ВХОДА
  # ---------------------------------------------------------------------------
  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile
      target: api-gateway
      args:
        REBUILD_DATE: ${REBUILD_DATE:-$(date +%Y%m%d%H%M%S)}
    container_name: api-gateway
    ports:
      - "8000:8000"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - SPRING_CLOUD_COMPATIBILITY_VERIFIER_ENABLED=false
      # ELK интеграция
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - sandbox-network
    depends_on:
      - service-one
      - service-two
      - kafka
      - logstash
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # SERVICE-ONE - ОСНОВНОЙ БИЗНЕС-СЕРВИС
  # ---------------------------------------------------------------------------
  service-one:
    build:
      context: .
      dockerfile: Dockerfile
      target: service-one
      args:
        REBUILD_DATE: ${REBUILD_DATE:-$(date +%Y%m%d%H%M%S)}
    container_name: service-one
    ports:
      - "8080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - SPRING_KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      # База данных
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=sandbox
      - DB_USERNAME=postgres
      - DB_PASSWORD=postgres
      # Redis
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # ELK интеграция
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - sandbox-network
    depends_on:
      - kafka
      - postgres
      - redis
      - logstash
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # SERVICE-TWO - СЕРВИС-ПОТРЕБИТЕЛЬ СООБЩЕНИЙ
  # ---------------------------------------------------------------------------
  service-two:
    build:
      context: .
      dockerfile: Dockerfile
      target: service-two
      args:
        REBUILD_DATE: ${REBUILD_DATE:-$(date +%Y%m%d%H%M%S)}
    container_name: service-two
    ports:
      - "8081:8081"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - SPRING_KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      # ELK интеграция
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - sandbox-network
    depends_on:
      - service-one
      - kafka
      - logstash
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# =============================================================================
# СЕКЦИЯ СЕТЕЙ
# =============================================================================
networks:
  sandbox-network:
    driver: bridge

# =============================================================================
# СЕКЦИЯ VOLUMES (ПОСТОЯННОЕ ХРАНИЛИЩЕ)
# =============================================================================
volumes:
  postgres-data:
  redis-data:
  prometheus-data:
  grafana-data:
  # ELK volumes
  elasticsearch-data:

# =============================================================================
# ДОСТУПНЫЕ СЕРВИСЫ ПОСЛЕ ДОБАВЛЕНИЯ ELK:
# =============================================================================
# http://localhost:3000  - React фронтенд
# http://localhost:8000  - API Gateway
# http://localhost:3001  - Grafana
# http://localhost:9090  - Prometheus
# http://localhost:8090  - Kafka UI
# http://localhost:5601  - Kibana
# http://localhost:9200  - Elasticsearch API
# TCP 5000              - Logstash TCP input
